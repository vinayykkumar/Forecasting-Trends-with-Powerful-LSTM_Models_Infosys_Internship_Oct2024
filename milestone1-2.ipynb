{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46011 entries, 0 to 46010\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   DateTime       46011 non-null  object\n",
      " 1   Consumption    46011 non-null  int64 \n",
      " 2   Production     46011 non-null  int64 \n",
      " 3   Nuclear        46011 non-null  int64 \n",
      " 4   Wind           46011 non-null  int64 \n",
      " 5   Hydroelectric  46011 non-null  int64 \n",
      " 6   Oil and Gas    46011 non-null  int64 \n",
      " 7   Coal           46011 non-null  int64 \n",
      " 8   Solar          46011 non-null  int64 \n",
      " 9   Biomass        46011 non-null  int64 \n",
      "dtypes: int64(9), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(              DateTime  Consumption  Production  Nuclear  Wind  Hydroelectric  \\\n",
       " 0  2019-01-01 00:00:00         6352        6527     1395    79           1383   \n",
       " 1  2019-01-01 01:00:00         6116        5701     1393    96           1112   \n",
       " 2  2019-01-01 02:00:00         5873        5676     1393   142           1030   \n",
       " 3  2019-01-01 03:00:00         5682        5603     1397   191            972   \n",
       " 4  2019-01-01 04:00:00         5557        5454     1393   159            960   \n",
       " \n",
       "    Oil and Gas  Coal  Solar  Biomass  \n",
       " 0         1896  1744      0       30  \n",
       " 1         1429  1641      0       30  \n",
       " 2         1465  1616      0       30  \n",
       " 3         1455  1558      0       30  \n",
       " 4         1454  1458      0       30  ,\n",
       " None,\n",
       "         Consumption    Production       Nuclear          Wind  Hydroelectric  \\\n",
       " count  46011.000000  46011.000000  46011.000000  46011.000000   46011.000000   \n",
       " mean    6587.616440   6518.645628   1291.177501    792.310882    1857.052444   \n",
       " std     1043.654923    986.805018    236.549637    675.812712     692.592157   \n",
       " min     3889.000000   3315.000000    562.000000    -26.000000     175.000000   \n",
       " 25%     5773.000000   5814.000000   1347.000000    236.000000    1347.000000   \n",
       " 50%     6552.000000   6462.000000   1383.000000    592.000000    1747.000000   \n",
       " 75%     7321.000000   7176.000000   1405.000000   1205.000000    2265.000000   \n",
       " max     9615.000000   9886.000000   1457.000000   2811.000000    4434.000000   \n",
       " \n",
       "         Oil and Gas          Coal         Solar       Biomass  \n",
       " count  46011.000000  46011.000000  46011.000000  46011.000000  \n",
       " mean    1171.890418   1193.157332    156.688031     55.851862  \n",
       " std      434.748917    320.449368    229.502650     14.235554  \n",
       " min      198.000000    279.000000      0.000000     17.000000  \n",
       " 25%      858.000000    962.000000      0.000000     45.000000  \n",
       " 50%     1211.000000   1172.000000      2.000000     57.000000  \n",
       " 75%     1511.000000   1406.000000    280.000000     67.000000  \n",
       " max     2141.000000   2537.000000   1137.000000     89.000000  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\nithe\\OneDrive\\Desktop\\Infosys\\the_one\\electricityConsumptionAndProductioction.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure of the dataset\n",
    "data.head(), data.info(), data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45987, 24, 9),\n",
       " (45987,),\n",
       " (36789, 24, 9),\n",
       " (9198, 24, 9),\n",
       " (36789,),\n",
       " (9198,),\n",
       " Consumption      0\n",
       " Production       0\n",
       " Nuclear          0\n",
       " Wind             0\n",
       " Hydroelectric    0\n",
       " Oil and Gas      0\n",
       " Coal             0\n",
       " Solar            0\n",
       " Biomass          0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Parse `DateTime` and set it as the index\n",
    "data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "data.set_index('DateTime', inplace=True)\n",
    "\n",
    "# Step 2: Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Step 3: Scale the numeric data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Step 4: Convert scaled data back into a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
    "\n",
    "# Step 5: Prepare sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length, :])  # Input: Sequence of length `seq_length`\n",
    "        y.append(data[i + seq_length, 0])   # Target: Next value of `Consumption`\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Sequence length for LSTM\n",
    "sequence_length = 24  # Use 24 time steps (e.g., hours) to predict the next step\n",
    "\n",
    "# Prepare input (X) and output (y)\n",
    "X, y = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "# Split into training and testing sets (80-20 split)\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "X.shape, y.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape, missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36789, 24, 1), (9198, 24, 1), (36789, 1), (9198, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Data Preparation for Univariate Time Series (using \"Consumption\" column)\n",
    "# Extract the `Consumption` column for univariate analysis\n",
    "univariate_data = scaled_df[['Consumption']].values\n",
    "\n",
    "# Function to create sequences for univariate LSTM\n",
    "def create_univariate_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])  # Input: Sequence of `seq_length`\n",
    "        y.append(data[i + seq_length])   # Target: Next value in the sequence\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Sequence length\n",
    "seq_length = 24  # Use 24 time steps to predict the next step\n",
    "\n",
    "# Prepare sequences\n",
    "X_uni, y_uni = create_univariate_sequences(univariate_data, seq_length)\n",
    "\n",
    "# Split into training and testing sets (80-20 split)\n",
    "train_size = int(0.8 * len(X_uni))\n",
    "X_train_uni, X_test_uni = X_uni[:train_size], X_uni[train_size:]\n",
    "y_train_uni, y_test_uni = y_uni[:train_size], y_uni[train_size:]\n",
    "\n",
    "X_train_uni.shape, X_test_uni.shape, y_train_uni.shape, y_test_uni.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0306 - val_loss: 0.0029\n",
      "Epoch 2/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 3/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 9.9543e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 8.6984e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.7252e-04 - val_loss: 0.0011\n",
      "Epoch 6/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.2888e-04 - val_loss: 7.6154e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 9.4696e-04 - val_loss: 8.7771e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 8.9785e-04 - val_loss: 7.1691e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 8.3645e-04 - val_loss: 7.3798e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 7.9120e-04 - val_loss: 7.3990e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 7.9977e-04 - val_loss: 7.8282e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 7.5769e-04 - val_loss: 8.3727e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 7.5633e-04 - val_loss: 7.1290e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 6.6766e-04 - val_loss: 7.3277e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 6.6269e-04 - val_loss: 7.4481e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 5.8510e-04 - val_loss: 6.5890e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.9699e-04 - val_loss: 6.8919e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.8404e-04 - val_loss: 6.3764e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.7187e-04 - val_loss: 6.2659e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 5.6101e-04 - val_loss: 6.1112e-04\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 5.6806e-04\n",
      "Vanilla LSTM Test Loss: 0.0006111168186180294\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define the model\n",
    "vanilla_lstm_model = Sequential([\n",
    "    LSTM(50, activation='tanh', input_shape=(seq_length, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "vanilla_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "vanilla_lstm_model.fit(X_train_uni, y_train_uni, epochs=20, batch_size=64, validation_data=(X_test_uni, y_test_uni))\n",
    "\n",
    "# Evaluate the model\n",
    "vanilla_loss = vanilla_lstm_model.evaluate(X_test_uni, y_test_uni)\n",
    "print(f\"Vanilla LSTM Test Loss: {vanilla_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - loss: 0.0236 - val_loss: 0.0014\n",
      "Epoch 2/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 0.0013 - val_loss: 8.6426e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 4/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 9.2967e-04 - val_loss: 7.8699e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - loss: 9.1822e-04 - val_loss: 7.9555e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 9.2240e-04 - val_loss: 7.1711e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - loss: 8.3985e-04 - val_loss: 6.7051e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - loss: 7.7685e-04 - val_loss: 6.7564e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 6.8274e-04 - val_loss: 7.1053e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 6.3889e-04 - val_loss: 7.1106e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 6.1672e-04 - val_loss: 8.1223e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 6.2298e-04 - val_loss: 7.9155e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 5.8355e-04 - val_loss: 5.7187e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 5.4311e-04 - val_loss: 6.1138e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 5.3766e-04 - val_loss: 6.4834e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 5.3113e-04 - val_loss: 7.1437e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 5.2874e-04 - val_loss: 6.6751e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 4.9913e-04 - val_loss: 5.2546e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 4.9481e-04 - val_loss: 5.2357e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - loss: 5.0786e-04 - val_loss: 6.0954e-04\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.5067e-04\n",
      "Stacked LSTM Test Loss: 0.0006095375283621252\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm_model = Sequential([\n",
    "    LSTM(50, activation='tanh', return_sequences=True, input_shape=(seq_length, 1)),\n",
    "    LSTM(50, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "stacked_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "stacked_lstm_model.fit(X_train_uni, y_train_uni, epochs=20, batch_size=64, validation_data=(X_test_uni, y_test_uni))\n",
    "\n",
    "stacked_loss = stacked_lstm_model.evaluate(X_test_uni, y_test_uni)\n",
    "print(f\"Stacked LSTM Test Loss: {stacked_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.0344 - val_loss: 0.0026\n",
      "Epoch 2/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 3/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 8.2230e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 9.2924e-04 - val_loss: 8.0355e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 8.4979e-04 - val_loss: 6.6355e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.1054e-04 - val_loss: 6.2462e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 8.0576e-04 - val_loss: 6.1713e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 7.4508e-04 - val_loss: 5.8871e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 7.3070e-04 - val_loss: 5.5294e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 6.8383e-04 - val_loss: 7.3182e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 6.7048e-04 - val_loss: 5.5652e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 6.2739e-04 - val_loss: 5.7835e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 6.1284e-04 - val_loss: 5.5123e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.8176e-04 - val_loss: 6.0233e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.6914e-04 - val_loss: 5.6406e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 5.7201e-04 - val_loss: 5.0859e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 5.5124e-04 - val_loss: 6.2028e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.3161e-04 - val_loss: 5.9624e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 5.3787e-04 - val_loss: 5.7175e-04\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.5848e-04\n",
      "Bidirectional LSTM Test Loss: 0.0005717539461329579\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "bidirectional_lstm_model = Sequential([\n",
    "    Bidirectional(LSTM(50, activation='tanh', input_shape=(seq_length, 1))),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "bidirectional_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "bidirectional_lstm_model.fit(X_train_uni, y_train_uni, epochs=20, batch_size=64, validation_data=(X_test_uni, y_test_uni))\n",
    "\n",
    "bidirectional_loss = bidirectional_lstm_model.evaluate(X_test_uni, y_test_uni)\n",
    "print(f\"Bidirectional LSTM Test Loss: {bidirectional_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nithe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0343 - val_loss: 0.0020\n",
      "Epoch 2/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 3/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 4/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 5/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 7/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.8165e-04 - val_loss: 8.8129e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 9.1873e-04 - val_loss: 7.6127e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 8.6628e-04 - val_loss: 7.2269e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 8.3338e-04 - val_loss: 6.8545e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 7.6756e-04 - val_loss: 6.7846e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 7.1154e-04 - val_loss: 7.2764e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.7129e-04 - val_loss: 6.8133e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.4667e-04 - val_loss: 5.9637e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.3419e-04 - val_loss: 6.6730e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 6.0848e-04 - val_loss: 5.6055e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.7082e-04 - val_loss: 6.7710e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5.7939e-04 - val_loss: 5.9716e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 5.7583e-04 - val_loss: 5.5945e-04\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.4635e-04\n",
      "CNN-LSTM Test Loss: 0.0005594493704847991\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "\n",
    "cnn_lstm_model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(seq_length, 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(50, activation='tanh'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "cnn_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "cnn_lstm_model.fit(X_train_uni, y_train_uni, epochs=20, batch_size=64, validation_data=(X_test_uni, y_test_uni))\n",
    "\n",
    "cnn_lstm_loss = cnn_lstm_model.evaluate(X_test_uni, y_test_uni)\n",
    "print(f\"CNN-LSTM Test Loss: {cnn_lstm_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0320 - val_loss: 0.0049\n",
      "Epoch 2/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0019 - val_loss: 9.5099e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 8.5899e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 8.0436e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 8.6100e-04 - val_loss: 6.7868e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - loss: 8.3377e-04 - val_loss: 7.2157e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - loss: 7.7588e-04 - val_loss: 6.9820e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - loss: 7.1195e-04 - val_loss: 6.1994e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - loss: 6.7896e-04 - val_loss: 5.5436e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 6.4605e-04 - val_loss: 5.6355e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 6.1920e-04 - val_loss: 7.1587e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - loss: 6.2102e-04 - val_loss: 5.1645e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 6.2049e-04 - val_loss: 5.3434e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - loss: 6.0148e-04 - val_loss: 5.0701e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 6.1181e-04 - val_loss: 5.5828e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 5.7805e-04 - val_loss: 5.7532e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 31ms/step - loss: 5.7385e-04 - val_loss: 6.0013e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 5.8566e-04 - val_loss: 4.7122e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 5.5363e-04 - val_loss: 4.8883e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m575/575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - loss: 5.5089e-04 - val_loss: 5.9441e-04\n",
      "\u001b[1m288/288\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 5.8185e-04\n",
      "ConvLSTM Test Loss: 0.0005944088334217668\n"
     ]
    }
   ],
   "source": [
    "# Reshape data for ConvLSTM: (samples, timesteps, rows, columns, channels)\n",
    "X_train_clstm = X_train_uni.reshape((X_train_uni.shape[0], seq_length, 1, 1, 1))  # rows=1, channels=1\n",
    "X_test_clstm = X_test_uni.reshape((X_test_uni.shape[0], seq_length, 1, 1, 1))\n",
    "\n",
    "# ConvLSTM model\n",
    "convlstm_model = Sequential([\n",
    "    ConvLSTM2D(filters=64, kernel_size=(1, 1), activation='relu', input_shape=(seq_length, 1, 1, 1)),\n",
    "    Flatten(),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "convlstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "convlstm_model.fit(X_train_clstm, y_train_uni, epochs=20, batch_size=64, validation_data=(X_test_clstm, y_test_uni))\n",
    "\n",
    "# Evaluate the model\n",
    "convlstm_loss = convlstm_model.evaluate(X_test_clstm, y_test_uni)\n",
    "print(f\"ConvLSTM Test Loss: {convlstm_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
