# -*- coding: utf-8 -*-
"""multivariate lstm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gmbuoTVM6b7L0xBNx948M3gpolbcQBCA
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.model_selection import train_test_split

# Load the data
data_file = '/content/yahoo_data.xlsx'
data = pd.read_excel(data_file)

# Display the first few rows of the dataset
print("Data Preview:")
print(data.head())

# Ensure the data is numerical and clean (drop NA values)
data = data.dropna()

# Convert the 'Date' column to datetime objects if it's not already
data['Date'] = pd.to_datetime(data['Date'])

# Extract numerical features for scaling, excluding the 'Date' column
numerical_features = data.select_dtypes(include=np.number).columns.tolist()
data_to_scale = data[numerical_features]

#Normalize the numerical data using MinMaxScaler
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data_to_scale)

# Create a new DataFrame with scaled data and the original 'Date' column
data_scaled = pd.DataFrame(data_scaled, columns=numerical_features, index=data.index)
data_scaled['Date'] = data['Date']

# Convert the scaled data back to a DataFrame for clarity
data_scaled = pd.DataFrame(data_scaled, columns=data.columns)

# Define a function to create sequences for LSTM
def create_sequences(data, target_column, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:i + sequence_length].values)
        y.append(data[i + sequence_length, target_column])
    return np.array(X), np.array(y)

# Parameters for LSTM modeling
sequence_length = 10  # Example sequence length

target_column = 0  # Predicting the first column (change index as needed)

def create_sequences(data, target_column, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:i + sequence_length].values)
        # Use .iloc to access data by row and column index
        y.append(data.iloc[i + sequence_length, target_column])
    return np.array(X), np.array(y)

# Convert the scaled data back to a DataFrame for clarity
data_scaled = pd.DataFrame(data_scaled, columns=data.columns)
# Remove 'Date' column before creating sequences
data_scaled = data_scaled.drop(columns=['Date'])

# Define a function to create sequences for LSTM
def create_sequences(data, target_column, sequence_length):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:i + sequence_length].values)
        # Use .iloc to access data by row and column index
        y.append(data.iloc[i + sequence_length, target_column])
    return np.array(X), np.array(y)

# Parameters for LSTM modeling
sequence_length = 10  # Example sequence length
target_column = 0  # Predicting the first column (change index as needed)

# Call create_sequences to generate X and y
X, y = create_sequences(data_scaled, target_column, sequence_length) # Calling the function to create X and y

# Split into training and testing datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential([
    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),
    Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# Evaluate the model on the test data
loss = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}")

# Predict on test data
predictions = model.predict(X_test)

# Inverse transform predictions to original scale
# Reshape predictions to have the same number of features as the original data
predictions_reshaped = predictions.reshape(-1, 1)  # Reshape to (n_samples, 1)

# Create an array of zeros with the correct shape for the remaining features
zeros_array = np.zeros((predictions.shape[0], data_scaled.shape[1] - 1))

# Horizontally stack the predictions and zeros
transformed_data = np.hstack((predictions_reshaped, zeros_array))

# Apply inverse_transform
predictions_original_scale = scaler.inverse_transform(transformed_data)[:, 0]

# Display predictions and actual values (in original scale)
# Get the original minimum and scale for the target column
target_min = scaler.data_min_[target_column]
target_scale = scaler.data_range_[target_column]

# Inverse transform y_test using the target column's min and scale
y_test_original_scale = (y_test * target_scale) + target_min

print("Sample Predictions vs Actual:")
for i in range(10):
    print(f"Prediction: {predictions_original_scale[i]:.2f}, Actual: {y_test_original_scale[i]:.2f}")

from sklearn.metrics import accuracy_score

# Assuming 'predictions' and 'y_test' are already defined (from your previous code)
# and are in the original scale.

# If predictions are probabilities, convert them to class labels
# For example, if the threshold for classification is 0.5
# predicted_labels = (predictions > 0.5).astype(int)

# Calculate accuracy
# accuracy = accuracy_score(y_test, predicted_labels)
# print(f"Accuracy: {accuracy}")

#For Regression Task
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test_original_scale, predictions_original_scale)
print(f"Mean Absolute Error: {mae}")